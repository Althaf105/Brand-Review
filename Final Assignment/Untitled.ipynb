{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the connection with CustomVision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "ENDPOINT = \"XXXXXXXXXX\"\n",
    "\n",
    "# Replace with a valid key\n",
    "training_key = \"XXXXXXXXX\"\n",
    "prediction_key = \"XXXXXXXXXX\"\n",
    "prediction_resource_id = \"XXXXXXXXXX\"\n",
    "\n",
    "publish_iteration_name = \"classifyModel\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project = trainer.create_project(\"Final_assignment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two tags in the new project\n",
    "adidas_tag = trainer.create_tag(project.id, \"Adidas\")\n",
    "nike_tag = trainer.create_tag(project.id, \"Nike\")\n",
    "puma_tag = trainer.create_tag(project.id, \"Puma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_image_url = \"C:/Users/altha/althaf_docs/Sem 2/Social Data Mining Techniques/Final Assignment/Final Assignment - Images\"\n",
    "\n",
    "print(\"Adding images...\")\n",
    "\n",
    "image_list = []\n",
    "for file in os.listdir(base_image_url+\"/Adidas/\"):\n",
    "    with open(base_image_url+\"/Adidas/\"+ file, \"rb\") as image_contents:\n",
    "        print(\"Adidas/\" + file)\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[adidas_tag.id]))\n",
    "\n",
    "\n",
    "for file in os.listdir(base_image_url+\"/Nike/\"):\n",
    "    print(\"Nike/\" + file)\n",
    "    with open(base_image_url+\"/Nike/\"+file, \"rb\") as image_contents:\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[nike_tag.id]))\n",
    "\n",
    "\n",
    "for file in os.listdir(base_image_url+\"/Puma/\"):\n",
    "    print(\"Puma/\" + file)\n",
    "    with open(base_image_url+\"/Puma/\"+file, \"rb\") as image_contents:\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[puma_tag.id]))\n",
    "        \n",
    "upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=image_list))\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n",
    "\n",
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPuma: 13.98%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry\n",
    "\n",
    "ENDPOINT = \"XXXXXXXXXX\"\n",
    "training_key = \"XXXXXXXXXXXXXX\"\n",
    "prediction_key = \"XXXXXXXXXXXXX\"\n",
    "prediction_resource_id = \"XXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "publish_iteration_name = \"classifyModel\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
    "\n",
    "project = trainer.get_project(\"611bc936-654c-4a48-82e9-703ed40708a7\")\n",
    "\n",
    "with open(r\"C:\\Users\\altha\\althaf_docs\\Sem 2\\Social Data Mining Techniques\\Final Assignment\\Final Assignment - Images\\Puma\\test\\shoes_ia56544.jpg\", \"rb\") as image_contents:\n",
    "    results = predictor.classify_image(\n",
    "        project.id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "    # Display the results.\n",
    "    \n",
    "    print(\"\\t\" + results.predictions[0].tag_name +\n",
    "              \": {0:.2f}%\".format(results.predictions[0].probability * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
